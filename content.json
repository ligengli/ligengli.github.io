{"meta":{"title":"Hexo","subtitle":null,"description":null,"author":"Li Geng","url":"http://yoursite.com","root":"/"},"pages":[{"title":"about","date":"2019-08-06T05:59:00.000Z","updated":"2019-08-06T05:59:00.559Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":""},{"title":"tags","date":"2019-08-06T05:59:08.000Z","updated":"2019-08-06T05:59:08.204Z","comments":true,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""},{"title":"categories","date":"2019-08-06T06:03:43.000Z","updated":"2019-08-06T06:03:43.194Z","comments":true,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"ubuntu 18 最大化、最小化、关闭按钮移动到左侧","slug":"ubuntu-icon","date":"2019-08-19T11:04:52.000Z","updated":"2019-08-19T11:11:44.934Z","comments":true,"path":"2019/08/19/ubuntu-icon/","link":"","permalink":"http://yoursite.com/2019/08/19/ubuntu-icon/","excerpt":"","text":"Ubuntu 18.04 的最大化、最小化和关闭按钮默认放在了右面，参考这篇博客发现执行，调整按钮到左边。 1gsettings set org.gnome.desktop.wm.preferences button-layout ‘close,maximize,minimize:’ 这样做后，关闭按钮不见了！！！ 执行 1gsettings set org.gnome.desktop.wm.preferences button-layout ‘close,close,maximize,minimize:’ 即重复一次 close 搞定。原因不清楚！感觉第一个按钮会被覆盖！","categories":[],"tags":[{"name":"ubuntu notes ui","slug":"ubuntu-notes-ui","permalink":"http://yoursite.com/tags/ubuntu-notes-ui/"}]},{"title":"变脸 (4) --- 视频","slug":"changeFace-4","date":"2019-08-12T06:41:03.000Z","updated":"2019-08-12T07:04:28.583Z","comments":true,"path":"2019/08/12/changeFace-4/","link":"","permalink":"http://yoursite.com/2019/08/12/changeFace-4/","excerpt":"","text":"总序“换脸”Python实现共分为四个部分，第一部分是原理讲解，第二部分是Python实现，第三部分是效果改进，前三部分都是单张图片，第四部分是应用到视频。 网上的很多教程没有原理讲解，所以也许可以照猫画虎，但没有总体的理解，就很难有自己的改进方法，希望本四次的分享对你有帮助。 第四部分 视频视频不过是一张一张的图片，在上一篇的基础上，用 opencv 实现读取视频，即可完成换脸。但之前需要做一件视频，就是判断当前帧里面是否只有一个人，代码如下： 1234def find_one_face(image): # dectetor 是人脸检测器 face_rect = detector(image, 1) return len(face_rect) == 1 此外，我们新建 change_face_video() 函数来实现显示视频： 1234567891011121314151617181920def change_face_video(target_face_file, camera=0): cap = cv2.VideoCapture(camera) target_face = cv2.imread(target_face_file) # 为了保存处理后的视频 fourcc = cv2.VideoWriter_fourcc(*'XVID') out = cv2.VideoWriter('output.avi',fourcc, 20.0, (640,480)) while (cap.isOpened()): hasFrame, frame = cap.read() # print(frame.shape, target_face.shape) new_face = frame if hasFrame and find_one_face(frame): new_face = change_face(frame, target_face) cv2.imshow('new_face', new_face) out.write(frame) # 把帧写入视频 if cv2.waitKey(1) &amp; 0xFF == ord('q'): break cv2.waitKey(0) cap.release()#释放摄像头 cv2.destroyAllWindows()#删除全部窗口 里面需要调用 change_face() 函数，change_face() 也要做一些简单修改，修改后如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445def change_face(img1, img2): boy = img1 girl = img2 boy_landmarks = get_landmark(boy) girl_landmarks = get_landmark(girl) # 获取变化矩阵， OVERLAY_POINTS 是上面定义的关键点下标 trans_mat = transformation_from_points( boy_landmarks[OVERLAY_POINTS], girl_landmarks[OVERLAY_POINTS] ) # 先得到 boy 和 warped_girl 的掩模，再取两个掩模的白色部分的并集 # 这样得到的掩模 combined_mask 就包含了两张脸所在的范围 boy_mask = get_face_mask(boy, boy_landmarks) girl_mask = get_face_mask(girl, girl_landmarks) warped_girl_mask = warp_image(girl_mask, trans_mat, boy.shape) combined_mask = np.max([boy_mask, warped_girl_mask], axis=0) # 为了让整容的脸衔接更好，把掩模边缘进行高斯模糊一下，核大小可以自己试着取 combined_mask = cv2.GaussianBlur(combined_mask, (19, 19), 0) combined_mask = cv2.GaussianBlur(combined_mask, (13, 13), 0) combined_mask = cv2.GaussianBlur(combined_mask, (7, 7), 0) # warped_girl 是一张大小和 boy 一样大，并且脸对应的图片 warped_girl = warp_image(girl, trans_mat, boy.shape) warped_girl_color_correct = color_correct(boy, warped_girl, boy_landmarks) boy = boy.astype(np.float64) warped_girl = warped_girl.astype(np.float64) # 图片相加， boy, girl 的像素点取值为 0~255，boy_mask像素点取值为 0或1 renyao = boy * (1 - combined_mask) + warped_girl_color_correct * combined_mask # 为了正常显示，像素值应转换成整型 boy = boy.astype(np.uint8) warped_girl = warped_girl.astype(np.uint8) renyao = renyao.astype(np.uint8) return renyao ''' cv2.imshow('boy', boy) cv2.imshow('warped_girl', warped_girl) cv2.imshow('renyao', renyao) cv2.waitKey(0) ''' 完整代码如下，命名成 changeface.py，运行 python3 changeface.py 即可打开摄像头，显示变脸后的图片，可以试试把自己变成二师兄^-^ ！ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192# 变脸完整程序import sys, os, globimport numpy as np import dlibimport cv2# 预测器和模型的路径predictor_path = r'./model/shape_predictor_68_face_landmarks.dat'face_rec_model_path = r'./model/dlib_face_recognition_resnet_model_v1.dat'faces_folder_path = r'./faces/'# 声明一个人脸关键点预测器 predictor，全局变量detector = dlib.get_frontal_face_detector()predictor = dlib.shape_predictor(predictor_path)# 68个点，分别代表眼，口，鼻等关键点的位置，现在分开一下LEFT_EYE_POINTS = list(range(42, 48))RIGHT_EYE_POINTS = list(range(36, 42))LEFT_BROW_POINTS = list(range(22, 27))RIGHT_BROW_POINTS = list(range(17, 22))NOSE_POINTS = list(range(27, 35))MOUTH_POINTS = list(range(48, 61))# 我们要用的确定人脸的关键点列表OVERLAY_POINTS = [ LEFT_EYE_POINTS + RIGHT_EYE_POINTS + LEFT_BROW_POINTS + RIGHT_BROW_POINTS + NOSE_POINTS + MOUTH_POINTS,]# 特征数FEATHER_AMOUNT = 11# 获取脸部关键点def get_landmark(image): face_rect = detector(image, 1) if len(face_rect) != 1: print('No one face in one picture') else: return np.matrix([[p.x, p.y] for p in predictor(image, face_rect[0]).parts()])def find_one_face(image): face_rect = detector(image, 1) return len(face_rect) == 1# 使用普氏分析调整脸部# p1,p2分别是两张图的关键点landmarks列表# 返回结果是从 p2 到 p1 的仿射变换矩阵def transformation_from_points(p1, p2): p1 = p1.astype(np.float64) p2 = p2.astype(np.float64) c1 = np.mean(p1, axis=0) c2 = np.mean(p2, axis=0) p1 -= c1 p2 -= c2 s1 = np.std(p1) s2 = np.std(p2) p1 /= s1 p2 /= s2 U, S, Vt = np.linalg.svd(p1.T * p2) R = (U * Vt).T trans_mat = np.vstack([np.hstack(((s2 / s1)*R, c2.T-(s2/s1)*R*c1.T)), np.matrix([0., 0., 1.])]) return trans_mat# 把 image 变成 dshape 大小，并用仿射矩阵 M 进行变化，这里的M就是上面的 trans_matdef warp_image(image, M, dshape): output_image = np.zeros(dshape, dtype=image.dtype) cv2.warpAffine(image, M[:2], (dshape[1], dshape[0]), dst=output_image, flags=cv2.WARP_INVERSE_MAP, borderMode=cv2.BORDER_TRANSPARENT) return output_image# 在img上绘制points点列表的凸包，Python参数默认引用，所以此处没用返回值def draw_convex_hull(img, points, color): points = cv2.convexHull(points) cv2.fillConvexPoly(img, points, color)# 获取人脸掩模def get_face_mask(img, landmarks): # 用一张灰度的图片来绘制 img = np.zeros(img.shape[:2], dtype=np.float64) for group in OVERLAY_POINTS: draw_convex_hull(img, landmarks[group], color=1) # 之前的 img 是单通道的灰度图，所以下面有三个 img img = np.array([img, img, img]).transpose((1, 2, 0)) return img# 根据瞳距进行颜色校正，这是一个经验方法COLOUR_CORRECT_BLUR_FRAC = 0.6def color_correct(im1, im2, landmarks1): # 根据左右眼之间的距离，乘以0.6，为高斯核的大小 blur_amount = COLOUR_CORRECT_BLUR_FRAC * np.linalg.norm( np.mean(landmarks1[LEFT_EYE_POINTS], axis=0) - np.mean(landmarks1[RIGHT_EYE_POINTS], axis=0)) blur_amount = int(blur_amount) if blur_amount % 2 == 0: blur_amount += 1 im1_blur = cv2.GaussianBlur(im1, (blur_amount, blur_amount), 0) im2_blur = cv2.GaussianBlur(im2, (blur_amount, blur_amount), 0) # 避免后面除以0，设一个 im2_blur_2 im2_blur[im2_blur &lt; 1] = 1 im2 = im2.astype(np.float64) im1_blur = im1_blur.astype(np.float64) im2_blur = im2_blur.astype(np.float64) # 类似 A * B / A im2_color_correct = im2 * im1_blur / im2_blur im2_color_correct[im2_color_correct &lt; 0] = 0 im2_color_correct[im2_color_correct &gt; 255] = 255 return im2_color_correct.astype(np.uint8)def change_face(img1, img2): boy = img1 girl = img2 boy_landmarks = get_landmark(boy) girl_landmarks = get_landmark(girl) # 获取变化矩阵， OVERLAY_POINTS 是上面定义的关键点下标 trans_mat = transformation_from_points( boy_landmarks[OVERLAY_POINTS], girl_landmarks[OVERLAY_POINTS] ) # 先得到 boy 和 warped_girl 的掩模，再取两个掩模的白色部分的并集 # 这样得到的掩模 combined_mask 就包含了两张脸所在的范围 boy_mask = get_face_mask(boy, boy_landmarks) girl_mask = get_face_mask(girl, girl_landmarks) warped_girl_mask = warp_image(girl_mask, trans_mat, boy.shape) combined_mask = np.max([boy_mask, warped_girl_mask], axis=0) # 为了让整容的脸衔接更好，把掩模边缘进行高斯模糊一下，核大小可以自己试着取 combined_mask = cv2.GaussianBlur(combined_mask, (19, 19), 0) combined_mask = cv2.GaussianBlur(combined_mask, (13, 13), 0) combined_mask = cv2.GaussianBlur(combined_mask, (7, 7), 0) # warped_girl 是一张大小和 boy 一样大，并且脸对应的图片 warped_girl = warp_image(girl, trans_mat, boy.shape) warped_girl_color_correct = color_correct(boy, warped_girl, boy_landmarks) boy = boy.astype(np.float64) warped_girl = warped_girl.astype(np.float64) # 图片相加， boy, girl 的像素点取值为 0~255，boy_mask像素点取值为 0或1 renyao = boy * (1 - combined_mask) + warped_girl_color_correct * combined_mask # 为了正常显示，像素值应转换成整型 boy = boy.astype(np.uint8) warped_girl = warped_girl.astype(np.uint8) renyao = renyao.astype(np.uint8) return renyao ''' cv2.imshow('boy', boy) cv2.imshow('warped_girl', warped_girl) cv2.imshow('renyao', renyao) cv2.waitKey(0) '''def change_face_video(target_face_file, camera=0): cap = cv2.VideoCapture(camera) target_face = cv2.imread(target_face_file) # 为了保存处理后的视频 fourcc = cv2.VideoWriter_fourcc(*'XVID') out = cv2.VideoWriter('output.avi',fourcc, 20.0, (640,480)) while (cap.isOpened()): hasFrame, frame = cap.read() # print(frame.shape, target_face.shape) new_face = frame if hasFrame and find_one_face(frame): new_face = change_face(frame, target_face) cv2.imshow('new_face', new_face) out.write(frame) # 把帧写入视频 if cv2.waitKey(1) &amp; 0xFF == ord('q'): break cv2.waitKey(0) cap.release()#释放摄像头 cv2.destroyAllWindows()#删除全部窗口# 把 faces/girl.jpeg 换成你想要变到的脸的图片change_face_video('faces/girl.jpeg')","categories":[],"tags":[{"name":"entertainment study","slug":"entertainment-study","permalink":"http://yoursite.com/tags/entertainment-study/"}]},{"title":"变脸 (3) --- 改进","slug":"changeFace-3","date":"2019-08-12T01:33:59.000Z","updated":"2019-08-12T06:39:12.568Z","comments":true,"path":"2019/08/12/changeFace-3/","link":"","permalink":"http://yoursite.com/2019/08/12/changeFace-3/","excerpt":"","text":"总序“换脸”Python实现共分为四个部分，第一部分是原理讲解，第二部分是Python实现，第三部分是效果改进，前三部分都是单张图片，第四部分是应用到视频。 网上的很多教程没有原理讲解，所以也许可以照猫画虎，但没有总体的理解，就很难有自己的改进方法，希望本四次的分享对你有帮助。 第三部分 改进在上一节，我们完成了变脸，但变脸后的效果很生硬，下面做一些改进！具体工作有两个方向： 调整掩模大小 调整颜色和亮度，让目标脸和原脸颜色一致 调整脸部衔接处的边缘，让其过渡自然 调整掩模大小我们要把图甲的人脸换成图乙中的人脸，之前已经变换图乙，让其图片中人脸和图甲中差不多（把变换后的图乙记作图丙）。图丙的人脸大小基本和图甲的一致，但两者还是会有偏差。那么我们可以分别得出图甲和图丙中人脸的掩模，取两个掩模的并集，效果如下： 上图最右面一张掩模白色部分是前两张掩模白色部分的并集。 图片亮度调整如果直接把脸分割，其效果如下： 两张脸肤色明显不同，一看就是造造假的。 下面进行改进，这里用到了高斯模糊，先模糊再去模糊，就得到肤色类似的图像，确实有几分神奇。比如第一张图的模糊效果如下，左边是原图，右边是模糊后的图： 下面是变换的代码： 123456789101112131415161718192021222324# 根据瞳距进行颜色校正，这是一个经验方法COLOUR_CORRECT_BLUR_FRAC = 0.6def color_correct(im1, im2, landmarks1): # 根据左右眼之间的距离，乘以0.6，为高斯核的大小 blur_amount = COLOUR_CORRECT_BLUR_FRAC * np.linalg.norm( np.mean(landmarks1[LEFT_EYE_POINTS], axis=0) - np.mean(landmarks1[RIGHT_EYE_POINTS], axis=0)) blur_amount = int(blur_amount) if blur_amount % 2 == 0: blur_amount += 1 im1_blur = cv2.GaussianBlur(im1, (blur_amount, blur_amount), 0) im2_blur = cv2.GaussianBlur(im2, (blur_amount, blur_amount), 0) # 避免后面除以0，设一个 im2_blur_2 im2_blur[im2_blur &lt; 1] = 1 im2 = im2.astype(np.float64) im1_blur = im2.astype(np.float64) im2_blur = im2_blur.astype(np.float64) # 类似 A * B / A im2_color_correct = im2 * im1_blur / im2_blur im2_color_correct[im2_color_correct &lt; 0] = 0 im2_color_correct[im2_color_correct &gt; 255] = 255 return im2_color_correct.astype(np.uint8) 上面的这个函数可以把图丙的脸的亮度变成我们需要的亮度，效果如下，最右面一张是亮度校准后的图片，希望的是和左面的boy的脸亮度一致，小姑娘的脸果然变黑了： 以上就换脸差不多了，看一下效果： 感觉还是有一丝丝的不和谐，头发被截下来，这个处理不了，不过脸的边缘可以再和谐一下。这可以通过把掩模用高斯核处理一下来完成，学了这么多，这个原因就不解释了，还不懂就说明没认真思考。 最终 change_face() 函数的代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344def change_face(img1, img2): boy = cv2.imread(img1) girl = cv2.imread(img2) boy_landmarks = get_landmark(boy) girl_landmarks = get_landmark(girl) # 获取变化矩阵， OVERLAY_POINTS 是上面定义的关键点下标 trans_mat = transformation_from_points( boy_landmarks[OVERLAY_POINTS], girl_landmarks[OVERLAY_POINTS] ) # 先得到 boy 和 warped_girl 的掩模，再取两个掩模的白色部分的并集 # 这样得到的掩模 combined_mask 就包含了两张脸所在的范围 boy_mask = get_face_mask(boy, boy_landmarks) girl_mask = get_face_mask(girl, girl_landmarks) warped_girl_mask = warp_image(girl_mask, trans_mat, boy.shape) combined_mask = np.max([boy_mask, warped_girl_mask], axis=0) # 为了让整容的脸衔接更好，把掩模边缘进行高斯模糊一下，核大小可以自己试着取 combined_mask = cv2.GaussianBlur(combined_mask, (19, 19), 0) combined_mask = cv2.GaussianBlur(combined_mask, (13, 13), 0) combined_mask = cv2.GaussianBlur(combined_mask, (7, 7), 0) # warped_girl 是一张大小和 boy 一样大，并且脸对应的图片 warped_girl = warp_image(girl, trans_mat, boy.shape) warped_girl_color_correct = color_correct(boy, warped_girl, boy_landmarks) boy = boy.astype(np.float64) warped_girl = warped_girl.astype(np.float64) # 图片相加， boy, girl 的像素点取值为 0~255，boy_mask像素点取值为 0或1 renyao = boy * (1 - combined_mask) + warped_girl_color_correct * combined_mask # 为了正常显示，像素值应转换成整型 boy = boy.astype(np.uint8) warped_girl = warped_girl.astype(np.uint8) renyao = renyao.astype(np.uint8) cv2.imshow('boy', boy) cv2.imshow('warped_girl', warped_girl) cv2.imshow('renyao', renyao) cv2.waitKey(0)change_face('faces/boy.jpeg', 'faces/girl.jpeg') 效果如下，因为有头发原因，上不不是很好，但脸部基本可以： 下面还有一个猴哥和八戒的变换： 把大师兄试着换成自己头像吧，enjoy it! 完整代码如下，除了增加 color_correct() 函数已经改动一下 change_face()外，其他函数和第（2）部分的一样： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162import sys, os, globimport numpy as np import dlibimport cv2# 预测器和模型的路径predictor_path = r'./model/shape_predictor_68_face_landmarks.dat'face_rec_model_path = r'./model/dlib_face_recognition_resnet_model_v1.dat'faces_folder_path = r'./faces/'# 声明一个人脸关键点预测器 predictor，全局变量detector = dlib.get_frontal_face_detector()predictor = dlib.shape_predictor(predictor_path)# 68个点，分别代表眼，口，鼻等关键点的位置，现在分开一下LEFT_EYE_POINTS = list(range(42, 48))RIGHT_EYE_POINTS = list(range(36, 42))LEFT_BROW_POINTS = list(range(22, 27))RIGHT_BROW_POINTS = list(range(17, 22))NOSE_POINTS = list(range(27, 35))MOUTH_POINTS = list(range(48, 61))# 我们要用的确定人脸的关键点列表OVERLAY_POINTS = [ LEFT_EYE_POINTS + RIGHT_EYE_POINTS + LEFT_BROW_POINTS + RIGHT_BROW_POINTS + NOSE_POINTS + MOUTH_POINTS,]# 特征数FEATHER_AMOUNT = 11# 获取脸部关键点def get_landmark(image): face_rect = detector(image, 1) if len(face_rect) != 1: print('No one face in one picture') else: return np.matrix([[p.x, p.y] for p in predictor(image, face_rect[0]).parts()])# 使用普氏分析调整脸部# p1,p2分别是两张图的关键点landmarks列表# 返回结果是从 p2 到 p1 的仿射变换矩阵def transformation_from_points(p1, p2): p1 = p1.astype(np.float64) p2 = p2.astype(np.float64) c1 = np.mean(p1, axis=0) c2 = np.mean(p2, axis=0) p1 -= c1 p2 -= c2 s1 = np.std(p1) s2 = np.std(p2) p1 /= s1 p2 /= s2 U, S, Vt = np.linalg.svd(p1.T * p2) R = (U * Vt).T trans_mat = np.vstack([np.hstack(((s2 / s1)*R, c2.T-(s2/s1)*R*c1.T)), np.matrix([0., 0., 1.])]) return trans_mat# 把 image 变成 dshape 大小，并用仿射矩阵 M 进行变化，这里的M就是上面的 trans_matdef warp_image(image, M, dshape): output_image = np.zeros(dshape, dtype=image.dtype) cv2.warpAffine(image, M[:2], (dshape[1], dshape[0]), dst=output_image, flags=cv2.WARP_INVERSE_MAP, borderMode=cv2.BORDER_TRANSPARENT) return output_image# 在img上绘制points点列表的凸包，Python参数默认引用，所以此处没用返回值def draw_convex_hull(img, points, color): points = cv2.convexHull(points) cv2.fillConvexPoly(img, points, color)# 获取人脸掩模def get_face_mask(img, landmarks): # 用一张灰度的图片来绘制 img = np.zeros(img.shape[:2], dtype=np.float64) for group in OVERLAY_POINTS: draw_convex_hull(img, landmarks[group], color=1) # 之前的 img 是单通道的灰度图，所以下面有三个 img img = np.array([img, img, img]).transpose((1, 2, 0)) return img# Amount of blur to use during colour correction, as a fraction of the# pupillary distance. (pupillary:瞳距)# 根据瞳距进行颜色校正，这是一个经验方法COLOUR_CORRECT_BLUR_FRAC = 0.6def color_correct(im1, im2, landmarks1): # 根据左右眼之间的距离，乘以0.6，为高斯核的大小 blur_amount = COLOUR_CORRECT_BLUR_FRAC * np.linalg.norm( np.mean(landmarks1[LEFT_EYE_POINTS], axis=0) - np.mean(landmarks1[RIGHT_EYE_POINTS], axis=0)) blur_amount = int(blur_amount) if blur_amount % 2 == 0: blur_amount += 1 im1_blur = cv2.GaussianBlur(im1, (blur_amount, blur_amount), 0) im2_blur = cv2.GaussianBlur(im2, (blur_amount, blur_amount), 0) # 避免后面除以0，设一个 im2_blur_2 im2_blur[im2_blur &lt; 1] = 1 im2 = im2.astype(np.float64) im1_blur = im1_blur.astype(np.float64) im2_blur = im2_blur.astype(np.float64) # 类似 A * B / A im2_color_correct = im2 * im1_blur / im2_blur im2_color_correct[im2_color_correct &lt; 0] = 0 im2_color_correct[im2_color_correct &gt; 255] = 255 return im2_color_correct.astype(np.uint8)def change_face(img1, img2): boy = cv2.imread(img1) girl = cv2.imread(img2) boy_landmarks = get_landmark(boy) girl_landmarks = get_landmark(girl) # 获取变化矩阵， OVERLAY_POINTS 是上面定义的关键点下标 trans_mat = transformation_from_points( boy_landmarks[OVERLAY_POINTS], girl_landmarks[OVERLAY_POINTS] ) # 先得到 boy 和 warped_girl 的掩模，再取两个掩模的白色部分的并集 # 这样得到的掩模 combined_mask 就包含了两张脸所在的范围 boy_mask = get_face_mask(boy, boy_landmarks) girl_mask = get_face_mask(girl, girl_landmarks) warped_girl_mask = warp_image(girl_mask, trans_mat, boy.shape) combined_mask = np.max([boy_mask, warped_girl_mask], axis=0) # 为了让整容的脸衔接更好，把掩模边缘进行高斯模糊一下，核大小可以自己试着取 combined_mask = cv2.GaussianBlur(combined_mask, (19, 19), 0) combined_mask = cv2.GaussianBlur(combined_mask, (13, 13), 0) combined_mask = cv2.GaussianBlur(combined_mask, (7, 7), 0) # warped_girl 是一张大小和 boy 一样大，并且脸对应的图片 warped_girl = warp_image(girl, trans_mat, boy.shape) warped_girl_color_correct = color_correct(boy, warped_girl, boy_landmarks) boy = boy.astype(np.float64) warped_girl = warped_girl.astype(np.float64) # 图片相加， boy, girl 的像素点取值为 0~255，boy_mask像素点取值为 0或1 renyao = boy * (1 - combined_mask) + warped_girl_color_correct * combined_mask # 为了正常显示，像素值应转换成整型 boy = boy.astype(np.uint8) warped_girl = warped_girl.astype(np.uint8) renyao = renyao.astype(np.uint8) cv2.imshow('Wukong Sun', boy) cv2.imshow('Bajie Zhu', warped_girl) cv2.imshow('Who are you?', renyao) cv2.waitKey(0)change_face('faces/swk.jpeg', 'faces/zbj_2.jpeg')","categories":[],"tags":[{"name":"entertainment study","slug":"entertainment-study","permalink":"http://yoursite.com/tags/entertainment-study/"}]},{"title":"变脸 (2) --- 实现","slug":"changeFace-2","date":"2019-08-06T06:49:21.000Z","updated":"2019-08-12T12:54:56.665Z","comments":true,"path":"2019/08/06/changeFace-2/","link":"","permalink":"http://yoursite.com/2019/08/06/changeFace-2/","excerpt":"","text":"总序“换脸”Python实现共分为四个部分，第一部分是原理讲解，第二部分是Python实现，第三部分是效果改进，前三部分都是单张图片，第四部分是应用到视频。 网上的很多教程没有原理讲解，所以也许可以照猫画虎，但没有总体的理解，就很难有自己的改进方法，希望本四次的分享对你有帮助。 第二部分 Python3实现在第一部分中，我们提到，换脸主要包括以下步骤： 1. 确定人脸位置2. 把图乙的人脸大小和方向调节得和图甲中的差不多3. 挖掉图甲中原来的人脸，换成图乙中的人脸下面我们依次来实现。 准备 Python包准备 ​ 我使用的是Ubuntu系统，Windows类似，用到的Python3 的主要有 $dlib$, $opencv$ 和$numpy$，请自行安装。 导入包代码如下： 1234import sys, osimport numpy as np import dlibimport cv2 文件夹 本项目的文件夹如下，face 是根目录，下面有个 changeFace.py ，写代码，与 changeFace.py 同级建两个文件夹，一个 model/ ，用来放模型，一个 faces/ ，用来放图片。 face/ changeFace.py model/ faces/ dlib 训练结果下载 对于确定人脸的关键点，已经有训练好的模型，官网下载 shape_predictor_68_face_landmarks.dat 和 dlib_face_recognition_resnet_model_v1.dat 文件。放在上一步说的 model/ 文件夹下。 图片准备 随便找两张只有一个人的正脸的图片，图片大小可以不一样，最好一男一女，这样换脸后也比较明显。分别命名成 boy.jpeg 和 girl.jpeg。我们的目标给男孩子换上女孩的脸^-^。 使用dlib预测器下面使用dlib预测器，做一些初始化。 1234567891011121314151617181920212223242526272829303132import sys, os, globimport numpy as np import dlibimport cv2# 预测器和模型的路径predictor_path = r'./model/shape_predictor_68_face_landmarks.dat'face_rec_model_path = r'./model/dlib_face_recognition_resnet_model_v1.dat'faces_folder_path = r'./faces/'# 声明一个人脸关键点预测器 predictor，全局变量detector = dlib.get_frontal_face_detector()predictor = dlib.shape_predictor(predictor_path)# 68个点，分别代表眼，口，鼻等关键点的位置，现在分开一下LEFT_EYE_POINTS = list(range(42, 48))RIGHT_EYE_POINTS = list(range(36, 42))LEFT_BROW_POINTS = list(range(22, 27))RIGHT_BROW_POINTS = list(range(17, 22))NOSE_POINTS = list(range(27, 35))MOUTH_POINTS = list(range(48, 61))# 我们要用的确定人脸的关键点列表OVERLAY_POINTS = [ LEFT_EYE_POINTS + RIGHT_EYE_POINTS + LEFT_BROW_POINTS + RIGHT_BROW_POINTS + NOSE_POINTS + MOUTH_POINTS,]# 特征数FEATHER_AMOUNT = 11 获取脸部关键点1234567891011121314# 获取脸部关键点def get_landmark(image): face_rect = detector(image, 1) if len(face_rect) != 1: print('No one face in one picture') else: return np.matrix([[p.x, p.y] for p in predictor(image, face_rect[0]).parts()])# 测试 get_landmark(img) 是否正常， 可不写def test_get_landmark(): for img_path in glob.glob(os.path.join(faces_folder_path, \"*.jpeg\")): img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE) landmarks = get_landmark(img) print(landmarks) 运行 test_get_landmark()， 可以看见输出一些两列的矩阵，每行代表一个点。 人脸对齐两张图片上的脸的大小和方向很可能是不同的，要换脸，那把脸变得差不多大是必须的。这个过程使用 Procrustes analysis（普氏分析），具体细节可以参考这里 。其实主要也是通过平移、旋转等仿射变化实现。代码如下： 123456789101112131415161718192021222324# 使用普氏分析调整脸部# p1,p2分别是两张图的关键点landmarks列表# 返回结果是从 p2 到 p1 的仿射变换矩阵def transformation_from_points(p1, p2): p1 = p1.astype(np.float64) p2 = p2.astype(np.float64) c1 = np.mean(p1, axis=0) c2 = np.mean(p2, axis=0) p1 -= c1 p2 -= c2 s1 = np.std(p1) s2 = np.std(p2) p1 /= s1 p2 /= s2 U, S, Vt = np.linalg.svd(p1.T * p2) R = (U * Vt).T trans_mat = np.vstack([np.hstack(((s2 / s1)*R, c2.T-(s2/s1)*R*c1.T)), np.matrix([0., 0., 1.])]) return trans_mat 下面具体利用上面的仿射变化函数 trans_mat 及图片大小，进行变化 123456789101112131415161718192021222324252627# 把 image 变成 dshape 大小，并用仿射矩阵 M 进行变化，这里的M就是上面的 trans_matdef warp_image(image, M, dshape): output_image = np.zeros(dshape, dtype=image.dtype) cv2.warpAffine(image, M[:2], (dshape[1], dshape[0]), dst=output_image, flags=cv2.WARP_INVERSE_MAP, borderMode=cv2.BORDER_TRANSPARENT) return output_image# 测试函数，可不写def test_wrap_image(): boy = cv2.imread(r'./faces/boy.jpeg') girl = cv2.imread(r'./faces/girl.jpeg') cv2.imshow(\"boy\", boy) cv2.imshow(\"girl_2\", girl) boy_landmarks = get_landmark(boy) girl_landmarks = get_landmark(girl) trans_mat = transformation_from_points( boy_landmarks, girl_landmarks) output_image = wrap_image(girl, trans_mat, dshape=boy.shape) cv2.imshow(\"result\", output_image) cv2.waitKey(0) cv2.destroyAllWindows() 运行 test_wrap_image()， 效果如下： 多余的背景是我的桌面，上面是截图。最右面一张是变化后的效果，可以看其脸型大小和图片尺寸都和 boy 大小差不多了。 获取人脸掩模先用 boy 的脸来做实验，其实脸主要看眼睛、鼻子和嘴巴的位置，我就要这几个关键部位。那先找出脸的形状，这个用 opencv 的凸包函数 convexHull() 来实现。 右图就是左图脸的掩模。代码实现如下： 123456789101112131415161718192021222324# 在img上绘制points点列表的凸包，Python参数默认引用，所以此处没用返回值def draw_convex_hull(img, points, color): points = cv2.convexHull(points) cv2.fillConvexPoly(img, points, color)# 获取人脸掩模def get_face_mask(img, landmarks): # 用一张灰度的图片来绘制 img = np.zeros(img.shape[:2], dtype=np.float64) for group in OVERLAY_POINTS: draw_convex_hull(img, landmarks[group], color=1) # 之前的 img 是单通道的灰度图，所以下面有三个 img img = np.array([img, img, img]).transpose((1, 2, 0)) return img# 测试函数， 可不写。def test_get_face_mask(): boy = cv2.imread(r'./faces/boy.jpeg') boy_landmarks = get_landmark(boy) boy_mask = get_face_mask(boy, boy_landmarks) cv2.imshow(\"boy\", boy) cv2.imshow(\"boy_mask\", boy_mask) cv2.waitKey(0) cv2.destroyAllWindows() 运行 test_get_face_mask()， 效果如上。 换脸到上面，基本工作完成了，那就来看看怎么让 boy 有 girl 的脸。下面依次实现 把 girl 的脸变成和 boy 一样大小； 拿到 girl 的脸和 boy 去掉脸的剩下部分，这步用掩模辅助实现。其实这里只有一个掩模，因为两张脸认为一样大，这样两张脸可以无缝连接； 用矩阵加法和对应元素相乘的方法实现换脸，因为图片颜色为 0255，这里要变成01。 下面是代码实现： 1234567891011121314151617181920212223242526272829303132def change_face(): boy = cv2.imread('faces/boy.jpeg') girl = cv2.imread('faces/girl.jpeg') boy_landmarks = get_landmark(boy) girl_landmarks = get_landmark(girl) # 获取变化矩阵， OVERLAY_POINTS 是上面定义的关键点下标 trans_mat = transformation_from_points( boy_landmarks[OVERLAY_POINTS], girl_landmarks[OVERLAY_POINTS] ) # 掩模就用 boy_mask就好 boy_mask = get_face_mask(boy, boy_landmarks) # warped_girl 是一张大小和 boy 一样大，并且脸对应的图片 warped_girl = warp_image(girl, trans_mat, boy.shape) boy = boy.astype(np.float64) warped_girl = warped_girl.astype(np.float64) # 图片相加， boy, girl 的像素点取值为 0~255，boy_mask像素点取值为 0或1 renyao = boy * (1 - boy_mask) + warped_girl * boy_mask # 为了正常显示，像素值应转换成整型 boy = boy.astype(np.uint8) warped_girl = warped_girl.astype(np.uint8) renyao = renyao.astype(np.uint8) cv2.imshow('boy', boy) cv2.imshow('warped_girl', warped_girl) cv2.imshow('renyao', renyao) cv2.waitKey(0) 运行 change_face()， 即可看见拭目以待的效果！如下，好看不？ 从左到右依次为原始boy，调整脸和图片大小后的 girl，换脸后的boy（人妖）。 总结以上就是换脸Python实现的全部内容了，可以看出换脸后及其不自然，下面一节来完善一下。汇总一下看到最终效果的代码。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125import sys, os, globimport numpy as np import dlibimport cv2# 预测器和模型的路径predictor_path = r'./model/shape_predictor_68_face_landmarks.dat'face_rec_model_path = r'./model/dlib_face_recognition_resnet_model_v1.dat'faces_folder_path = r'./faces/'# 声明一个人脸关键点预测器 predictor，全局变量detector = dlib.get_frontal_face_detector()predictor = dlib.shape_predictor(predictor_path)# 68个点，分别代表眼，口，鼻等关键点的位置，现在分开一下LEFT_EYE_POINTS = list(range(42, 48))RIGHT_EYE_POINTS = list(range(36, 42))LEFT_BROW_POINTS = list(range(22, 27))RIGHT_BROW_POINTS = list(range(17, 22))NOSE_POINTS = list(range(27, 35))MOUTH_POINTS = list(range(48, 61))# 我们要用的确定人脸的关键点列表OVERLAY_POINTS = [ LEFT_EYE_POINTS + RIGHT_EYE_POINTS + LEFT_BROW_POINTS + RIGHT_BROW_POINTS + NOSE_POINTS + MOUTH_POINTS,]# 特征数FEATHER_AMOUNT = 11# 获取脸部关键点def get_landmark(image): face_rect = detector(image, 1) if len(face_rect) != 1: print('No one face in one picture') else: return np.matrix([[p.x, p.y] for p in predictor(image, face_rect[0]).parts()])# 使用普氏分析调整脸部# p1,p2分别是两张图的关键点landmarks列表# 返回结果是从 p2 到 p1 的仿射变换矩阵def transformation_from_points(p1, p2): p1 = p1.astype(np.float64) p2 = p2.astype(np.float64) c1 = np.mean(p1, axis=0) c2 = np.mean(p2, axis=0) p1 -= c1 p2 -= c2 s1 = np.std(p1) s2 = np.std(p2) p1 /= s1 p2 /= s2 U, S, Vt = np.linalg.svd(p1.T * p2) R = (U * Vt).T trans_mat = np.vstack([np.hstack(((s2 / s1)*R, c2.T-(s2/s1)*R*c1.T)), np.matrix([0., 0., 1.])]) return trans_mat# 把 image 变成 dshape 大小，并用仿射矩阵 M 进行变化，这里的M就是上面的 trans_matdef warp_image(image, M, dshape): output_image = np.zeros(dshape, dtype=image.dtype) cv2.warpAffine(image, M[:2], (dshape[1], dshape[0]), dst=output_image, flags=cv2.WARP_INVERSE_MAP, borderMode=cv2.BORDER_TRANSPARENT) return output_image# 在img上绘制points点列表的凸包，Python参数默认引用，所以此处没用返回值def draw_convex_hull(img, points, color): points = cv2.convexHull(points) cv2.fillConvexPoly(img, points, color)# 获取人脸掩模def get_face_mask(img, landmarks): # 用一张灰度的图片来绘制 img = np.zeros(img.shape[:2], dtype=np.float64) for group in OVERLAY_POINTS: draw_convex_hull(img, landmarks[group], color=1) # 之前的 img 是单通道的灰度图，所以下面有三个 img img = np.array([img, img, img]).transpose((1, 2, 0)) return imgdef change_face(): boy = cv2.imread('faces/boy.jpeg') girl = cv2.imread('faces/girl.jpeg') boy_landmarks = get_landmark(boy) girl_landmarks = get_landmark(girl) # 获取变化矩阵， OVERLAY_POINTS 是上面定义的关键点下标 trans_mat = transformation_from_points( boy_landmarks[OVERLAY_POINTS], girl_landmarks[OVERLAY_POINTS] ) # 掩模就用 boy_mask就好 boy_mask = get_face_mask(boy, boy_landmarks) # warped_girl 是一张大小和 boy 一样大，并且脸对应的图片 warped_girl = warp_image(girl, trans_mat, boy.shape) boy = boy.astype(np.float64) warped_girl = warped_girl.astype(np.float64) # 图片相加， boy, girl 的像素点取值为 0~255，boy_mask像素点取值为 0或1 renyao = boy * (1 - boy_mask) + warped_girl * boy_mask # 为了正常显示，像素值应转换成整型 boy = boy.astype(np.uint8) warped_girl = warped_girl.astype(np.uint8) renyao = renyao.astype(np.uint8) cv2.imshow('boy', boy) cv2.imshow('warped_girl', warped_girl) cv2.imshow('renyao', renyao) cv2.waitKey(0)change_face()","categories":[],"tags":[{"name":"entertainment study","slug":"entertainment-study","permalink":"http://yoursite.com/tags/entertainment-study/"}]},{"title":"变脸 (1) --- 原理","slug":"changeFace-1","date":"2019-08-03T02:35:25.000Z","updated":"2019-08-12T06:40:11.864Z","comments":true,"path":"2019/08/03/changeFace-1/","link":"","permalink":"http://yoursite.com/2019/08/03/changeFace-1/","excerpt":"","text":"总序“换脸”Python实现共分为四个部分，第一部分是原理讲解，第二部分是Python实现，第三部分是效果改进，前三部分都是单张图片，第四部分是应用到视频。 网上的很多教程没有原理讲解，所以也许可以照猫画虎，但没有总体的理解，就很难有自己的改进方法，希望本四次的分享对你有帮助。 第一部分 原理换脸原理很简单，就是两个图，把第一张图（图甲）中的人脸换成第二张图（图乙）中的人脸。具体分成4步： 1. 确定人脸位置2. 把图乙的人脸大小和方向调节得和图甲中的差不多3. 挖掉图甲中原来的人脸，换成图乙中的人脸当然，为了使人脸衔接更自然，会做一些简单的脸边缘的过渡，同时会做一些亮度、边缘模糊等调整。 步骤上面原理中的三个步骤，也是三个难题，其实很简单。我觉得没有必要从太细节上追究每一个点，但宏观上必须了解它大概是怎么进行的。 1. 确定人脸位置为了确定人脸位置，有专门训练好的 dlib 库，它会找出人脸的特征点（中图），dlib 是一个训练好的模型，可以直接下载其参数。然后用 opencv 的凸包函数得到人脸形状（右图）。此处不是将整张人脸截下，而是将眼睛，口，鼻等关键部位截出来，当然自己也可以截出整张脸。如下图，左图是原始图片，中图是 dlib 检测人脸，右图是最终得到包含关键部位的人脸的形状。 图1 确定人脸位置 这样，图样的方法处理图乙，得到人脸位置。 2. 把图乙的人脸大小和方向调节得和图甲中的差不多这个的实现主要用仿射变换，及一些图片的旋转、缩放、调整图片分辨率等方法，具体实现也比较麻烦，能从总体上知道那些函数功能这样就好。 3. 挖掉图甲中原来的人脸，换成图乙中的人脸这个用掩模的方法，就像图1中的最右面一张图，我有另外一张图，大小和其一致，但脸型部分全为0，其余部分全为1. 两张图相当于两个矩阵，两者对应元素相乘，就得到挖去脸的图片。此时如果我有另外一张脸，脸部全为1， 其余部分全是0，那么用两张图对应元素一一相加，就可以得到最终的换脸后的图片。 4. 衔接过渡脸的边缘用上面的方法换的脸，看上去很不自然。此时可以把“新脸”的亮度调整得和“旧脸”差不多，边缘进行一些模糊，让其过渡自然。 结语以上便是基本思路，有了这样的思路，就可以根据需要很好得进行算法修改。下面进入第二部分。","categories":[],"tags":[{"name":"entertainment study","slug":"entertainment-study","permalink":"http://yoursite.com/tags/entertainment-study/"}]}]}